from utils.imports import (
    ConversationalRetrievalChain,
    ConversationBufferMemory
)
import streamlit as st
from utils.api_handler import APIHandler
from utils.vectordb_utils import get_vectordb, rebuild_vectordb_for_files
from utils.model_utils import get_embedding_model
from config.config import VECTOR_DB_PATH
import logging
from langchain_core.prompts import PromptTemplate
from langchain_core.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)

logger = logging.getLogger(__name__)

# å®šä¹‰ç³»ç»Ÿæç¤ºå’Œäººç±»æç¤ºæ¨¡æ¿
SYSTEM_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚

ä¸Šä¸‹æ–‡: {context}

å†å²å¯¹è¯: {chat_history}
"""

HUMAN_TEMPLATE = """é—®é¢˜: {question}"""

# åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿
CHAT_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(SYSTEM_TEMPLATE),
    HumanMessagePromptTemplate.from_template(HUMAN_TEMPLATE)
])

def initialize_chat_history():
    """
    åˆå§‹åŒ–æˆ–è·å–èŠå¤©å†å²
    
    Returns:
        list: èŠå¤©å†å²åˆ—è¡¨
    """
    if "messages" not in st.session_state:
        st.session_state.messages = []
    return st.session_state.messages

def get_chat_qa_chain(llm, vectordb):
    """
    åˆ›å»ºèŠå¤©é—®ç­”é“¾
    
    Args:
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹
        vectordb: å‘é‡æ•°æ®åº“å®ä¾‹
    
    Returns:
        ConversationalRetrievalChain: é—®ç­”é“¾å®ä¾‹
    """
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        output_key="answer",
        return_messages=True
    )
    
    # ä¿®æ”¹æ£€ç´¢å‚æ•°
    retriever = vectordb.as_retriever(
        search_type="similarity",
        search_kwargs={
            "k": 3
        }
    )
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        return_source_documents=True,
        return_generated_question=False,
        combine_docs_chain_kwargs={"prompt": CHAT_PROMPT}
    )

def generate_response(user_input: str, qa_chain) -> tuple[str, list]:
    """ç”Ÿæˆå›ç­”"""
    try:
        # ä½¿ç”¨ qa_chain å¤„ç†é—®é¢˜
        response = qa_chain({"question": user_input})
        
        # ä»å“åº”ä¸­æå–ç­”æ¡ˆå’Œæ¥æºæ–‡æ¡£
        answer = response.get('answer', '')
        source_docs = response.get('source_documents', [])
        
        return answer, source_docs
        
    except Exception as e:
        logger.error(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}", []

def clean_response(response) -> str:
    """æ¸…ç†æ¨¡å‹å“åº”"""
    try:
        logger.info(f"åŸå§‹å“åº”: {response}")  # æ·»åŠ æ—¥å¿—
        
        if isinstance(response, str):
            return response.strip()
            
        # å¦‚æœæ˜¯ ChatZhipuAI çš„å“åº”
        if hasattr(response, 'content'):
            return response.content.strip()
            
        # å¦‚æœæ˜¯ ChatOllama çš„å“åº”
        if hasattr(response, 'message'):
            return response.message.content.strip()
            
        logger.error(f"æœªçŸ¥çš„å“åº”ç±»å‹: {type(response)}")
        return str(response)
        
    except Exception as e:
        logger.error(f"æ¸…ç†å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return f"å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}"

def display_chat_message(message, is_user=False):
    """
    æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯
    
    Args:
        message (str): æ¶ˆæ¯å†…å®¹
        is_user (bool): æ˜¯å¦ä¸ºç”¨æˆ·æ¶ˆæ¯
    """
    avatar = "ğŸ§‘â€ğŸ’»" if is_user else "ğŸ¤–"
    with st.chat_message(name="user" if is_user else "assistant", avatar=avatar):
        st.markdown(message)

def display_source_documents(documents):
    """
    æ˜¾ç¤ºæ¥æºæ–‡æ¡£
    
    Args:
        documents (list): æ¥æºæ–‡æ¡£åˆ—è¡¨
    """
    if documents:
        st.markdown("### å‚è€ƒæ¥æº")
        
        # ä½¿ç”¨ tabs ä»£æ›¿ expander
        tabs = st.tabs([f"æ¥æº {i+1}" for i in range(len(documents))])
        
        for i, (tab, doc) in enumerate(zip(tabs, documents)):
            with tab:
                st.markdown(doc.page_content)
                # if hasattr(doc.metadata, 'source') and doc.metadata.get('source'):
                #     st.caption(f"æ¥æº: {doc.metadata['source']}") 
                if doc.metadata and 'source' in doc.metadata:
                    st.caption(f"æ¥æº: {doc.metadata['source']}")